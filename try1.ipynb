{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d3adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import pandas\n",
    "\n",
    "\n",
    "from preprocess import preprocess_list, write_pkl\n",
    "# from rnn_w2v import run_testing, run_training, RNN_Model\n",
    "# from word_embedder_gensim import WordVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99768bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64697c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Ana\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "055c3a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ana\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fb2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5adc00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbtrain = pandas.read_csv(\"dbpedia_csv/\" + \"train.csv\", names=[\"label\", \"title\", \"content\"])\n",
    "# dbvalid = pandas.read_csv(paths.data + \"validation.csv\", names=[\"label\", \"title\", \"content\"])\n",
    "dbtest = pandas.read_csv(\"dbpedia_csv/\" + \"test.csv\", names=[\"label\", \"title\", \"content\"])\n",
    "\n",
    "\n",
    "train_docs = list(dbtrain[\"content\"])\n",
    "#valid_docs = list(dbvalid[\"content\"])\n",
    "test_docs = list(dbtest[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5130833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|█████████████████████████████████████████████████████████| 560000/560000 [07:54<00:00, 1180.26it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_train_docs = preprocess_list(train_docs)\n",
    "write_pkl(list(dbtrain[\"label\"]), list(dbtrain[\"title\"]), new_train_docs, mode=\"train_lem_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fb09528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing: 100%|███████████████████████████████████████████████████████████| 70000/70000 [00:51<00:00, 1359.18it/s]\n"
     ]
    }
   ],
   "source": [
    "new_test_docs = preprocess_list(test_docs)\n",
    "write_pkl(list(dbtest[\"label\"]), list(dbtest[\"title\"]), new_test_docs, mode=\"test_lem_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a6826",
   "metadata": {},
   "source": [
    "## tf-idf naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a68d30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bce8d1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prophecy fifth novel new york times bestselling author chris kuzneski published october 2009 penguin uk action thriller follows adventures jonathon payne david dj jones try decipher newly discovered manuscript written nostradamus book peaked 4 british fiction list stayed bestseller list several weeks putnam released american hardcover version july 2010'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47877aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, x_b, x_train = pickle.load(open(\"dbpedia_csv/\" + \"train_lem__preprocessed_vectorized.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, x_tb, x_test = pickle.load(open(\"dbpedia_csv/\" + \"test_lem__preprocessed_vectorized.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d722eb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abbott farnham e abbott limited british coachbuilding business based farnham surrey trading name 1929 major part output subcontract motor vehicle manufacturer business closed 1972'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d04a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unsigned guide online contact directory career guide uk music industry founded 2003 first published printed directory unsigned guide became online resource november 2011'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82180db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1faa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# x_train -> content\n",
    "# y_train -> labels\n",
    "\n",
    "# y_test -> labels\n",
    "# x_test -> content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20f843b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from training data : 51.339539 seconds\n",
      "n_samples: 560000, n_features: 682477\n"
     ]
    }
   ],
   "source": [
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = TfidfVectorizer() # or term frequency\n",
    "\n",
    "X_train_tf = tf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01ffcbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from test data : 7.214369 seconds\n",
      "n_samples: 70000, n_features: 682477\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "X_test_tf = tf_vectorizer.transform(x_test)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82023f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 3.293s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(X_train_tf, y_train)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a351093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.189s\n",
      "accuracy:   0.945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88      5000\n",
      "           1       0.94      0.97      0.96      5000\n",
      "           2       0.93      0.76      0.84      5000\n",
      "           3       0.98      0.99      0.98      5000\n",
      "           4       0.96      0.96      0.96      5000\n",
      "           5       0.96      0.99      0.97      5000\n",
      "           6       0.94      0.95      0.94      5000\n",
      "           7       0.97      0.98      0.98      5000\n",
      "           8       1.00      0.95      0.97      5000\n",
      "           9       1.00      0.98      0.99      5000\n",
      "          10       0.99      0.99      0.99      5000\n",
      "          11       0.88      0.99      0.93      5000\n",
      "          12       0.93      0.96      0.94      5000\n",
      "          13       0.85      0.92      0.89      5000\n",
      "\n",
      "    accuracy                           0.94     70000\n",
      "   macro avg       0.95      0.94      0.94     70000\n",
      "weighted avg       0.95      0.94      0.94     70000\n",
      "\n",
      "confusion matrix:\n",
      "[[4246   63   49   11   19  150   60    3    0    0    0  193   42  164]\n",
      " [  45 4859   14    3   26    4   34    1    3    0    0    0    1   10]\n",
      " [  51   24 3796   12   88    2   16    1    1    1    2  427  128  451]\n",
      " [   4    0   20 4940   15    7    3    1    0    0    0    2    6    2]\n",
      " [  22   27   45   17 4816   18   22    0    0    0    0    0   10   23]\n",
      " [  41    1    0    0    0 4937   10    3    0    1    0    0    2    5]\n",
      " [  68  103   12    3   16   22 4738   25    2    1    0    1    1    8]\n",
      " [   7    9    1    0    3   10   74 4880    8    2    3    0    0    3]\n",
      " [   5   52    2    0   11    3   76   87 4760    0    0    0    1    3]\n",
      " [   4    0    5   31    1    0    2    8    0 4884   52    1    4    8]\n",
      " [  16    1    3    0    0    1    4    1    0   18 4952    1    1    2]\n",
      " [   5    0   37    1    0    0    0    0    0    0    0 4928   22    7]\n",
      " [  11    1   28    7    4    9    1    0    0    0    0   45 4791  103]\n",
      " [ 105   20   67    8   21    5    8    0    0    1    3   21  144 4597]]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "y_pred = naive_bayes_classifier.predict(X_test_tf)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d935700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
