{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db1ca9ca",
   "metadata": {},
   "source": [
    "## We will only test XGBoost on Word2Vec because of memory issues with the Tf-Idf matrix for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8d9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1703b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 6,\n",
    "    'objective': 'multi:softmax',  # error evaluation for multiclass training\n",
    "    'num_class': 14,\n",
    "    # Set number of GPUs if available   \n",
    "    'tree_method': 'gpu_hist',\n",
    "    'gpu_id': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f0b5d",
   "metadata": {},
   "source": [
    "### full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9ca2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_vec_preprocessed_vectorized.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_vec_preprocessed_vectorized.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22293110",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABELS MUST BE FROM 0 TO 13 BECAUSE OF XGBOOST IMPLEMENTATION\n",
    "\n",
    "y_test = [y-1 for y in y_test]\n",
    "y_train = [y-1 for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28e2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7046a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### delete data to free space\n",
    "\n",
    "import sys \n",
    "import gc\n",
    "del x_train\n",
    "del x_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a390836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 81.020s\n",
      "test time:  1.311s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest time:  \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m test_time)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# print(classification_report(y_test, pred))\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# cm = confusion_matrix(y_test, pred)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# cm\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m score1 \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39maccuracy_score(y_test, \u001b[43my_pred\u001b[49m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy:   \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m score1)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(y_test, y_pred, target_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m14\u001b[39m)]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# print(classification_report(y_test, pred))\n",
    "# cm = confusion_matrix(y_test, pred)\n",
    "# cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a0bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      5000\n",
      "           1       0.95      0.95      0.95      5000\n",
      "           2       0.84      0.81      0.83      5000\n",
      "           3       0.97      0.97      0.97      5000\n",
      "           4       0.93      0.93      0.93      5000\n",
      "           5       0.94      0.96      0.95      5000\n",
      "           6       0.93      0.92      0.92      5000\n",
      "           7       0.97      0.97      0.97      5000\n",
      "           8       0.99      0.98      0.99      5000\n",
      "           9       0.96      0.96      0.96      5000\n",
      "          10       0.97      0.96      0.97      5000\n",
      "          11       0.94      0.96      0.95      5000\n",
      "          12       0.94      0.95      0.94      5000\n",
      "          13       0.86      0.86      0.86      5000\n",
      "\n",
      "    accuracy                           0.93     70000\n",
      "   macro avg       0.93      0.93      0.93     70000\n",
      "weighted avg       0.93      0.93      0.93     70000\n",
      "\n",
      "confusion matrix:\n",
      "[[4269   51   84   19   44  165   86   15    1    6   11   55   34  160]\n",
      " [  60 4732   21   13   53    6   69    8    5    1    4    0    7   21]\n",
      " [  92   26 4058   30  106    7   28    2    0    2    5  190   99  355]\n",
      " [   7    7   60 4867   16   23    6    0    0    3    1    0    3    7]\n",
      " [  37   60  130   22 4672   20   18    3    1    2    0    0    7   28]\n",
      " [ 148    3    4    4    9 4781   24    9    0    4    0    1    3   10]\n",
      " [  90   90   29    6   43   53 4598   63   11    2    1    0    4   10]\n",
      " [   2    7    2    1    8   16   56 4864   17   10    8    0    2    7]\n",
      " [   3    2    2    1    9    2   35   44 4896    2    1    0    0    3]\n",
      " [   3    0    4   10    2    4    4    9    0 4825  133    0    0    6]\n",
      " [  14    0    2    0    2    5    4    8    0  141 4821    1    0    2]\n",
      " [  13    0  115    2    2    6    2    1    0    2    1 4800   32   24]\n",
      " [  14    1   61   11    4    9    1    1    0    5    2   37 4756   98]\n",
      " [ 127   27  250   16   48   16   29    8    0    7    2   24  123 4323]]\n"
     ]
    }
   ],
   "source": [
    "score1 = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee234e",
   "metadata": {},
   "source": [
    "### half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aa94d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_vec_preprocessed_vectorized.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_vec_preprocessed_vectorized.pickle\", \"rb\"))\n",
    "\n",
    "y_train = y_train[slice(0, len(y_train), 2)]\n",
    "x_train = x_train[slice(0, len(x_train), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dc12b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LABELS MUST BE FROM 0 TO 13 BECAUSE OF XGBOOST IMPLEMENTATION\n",
    "\n",
    "y_test = [y-1 for y in y_test]\n",
    "y_train = [y-1 for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b6e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d07d88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "537"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### delete data to free space\n",
    "\n",
    "import sys \n",
    "import gc\n",
    "del x_train\n",
    "del x_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f96add8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 43.657s\n",
      "test time:  0.190s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b403ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      5000\n",
      "           1       0.94      0.95      0.94      5000\n",
      "           2       0.84      0.81      0.83      5000\n",
      "           3       0.98      0.97      0.97      5000\n",
      "           4       0.93      0.93      0.93      5000\n",
      "           5       0.93      0.96      0.94      5000\n",
      "           6       0.93      0.92      0.92      5000\n",
      "           7       0.97      0.97      0.97      5000\n",
      "           8       0.99      0.98      0.99      5000\n",
      "           9       0.97      0.96      0.97      5000\n",
      "          10       0.97      0.97      0.97      5000\n",
      "          11       0.94      0.96      0.95      5000\n",
      "          12       0.94      0.95      0.94      5000\n",
      "          13       0.86      0.86      0.86      5000\n",
      "\n",
      "    accuracy                           0.93     70000\n",
      "   macro avg       0.93      0.93      0.93     70000\n",
      "weighted avg       0.93      0.93      0.93     70000\n",
      "\n",
      "confusion matrix:\n",
      "[[4253   58   89   16   44  180   87   11    1    8    7   56   34  156]\n",
      " [  63 4730   22   13   53    6   70   11    5    0    3    0    5   19]\n",
      " [  91   29 4070   25  116   10   24    1    2    4    5  189  101  333]\n",
      " [  10    6   61 4854   24   22    5    3    0    5    1    2    3    4]\n",
      " [  39   57  116   26 4659   31   19    2    1    3    0    1    6   40]\n",
      " [ 139    3    3    2    7 4784   27   11    0    8    1    2    4    9]\n",
      " [  88   92   27    3   54   41 4595   67   14    2    0    1    6   10]\n",
      " [   6    7    2    1   11   15   59 4866   13    5    5    0    4    6]\n",
      " [   2    4    1    0    7    2   44   38 4897    2    1    0    0    2]\n",
      " [   4    0    4   10    4    6    5    8    0 4820  131    0    1    7]\n",
      " [  19    1    5    0    1    3    4    8    0  104 4849    1    0    5]\n",
      " [  16    0  114    4    5    4    2    2    0    3    3 4795   31   21]\n",
      " [  23    1   63    7    9    9    4    2    0    3    2   33 4738  106]\n",
      " [ 135   28  252   16   40   20   21    5    1    9    5   30  134 4304]]\n"
     ]
    }
   ],
   "source": [
    "score1 = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443c121",
   "metadata": {},
   "source": [
    "### fourth of the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b7f6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_vec_preprocessed_vectorized.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_vec_preprocessed_vectorized.pickle\", \"rb\"))\n",
    "\n",
    "y_train = y_train[slice(0, len(y_train), 4)]\n",
    "x_train = x_train[slice(0, len(x_train), 4)]\n",
    "\n",
    "\n",
    "## LABELS MUST BE FROM 0 TO 13 BECAUSE OF XGBOOST IMPLEMENTATION\n",
    "\n",
    "y_test = [y-1 for y in y_test]\n",
    "y_train = [y-1 for y in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a976ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d615c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### delete data to free space\n",
    "\n",
    "import sys \n",
    "import gc\n",
    "del x_train\n",
    "del x_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2718410a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 27.326s\n",
      "test time:  0.199s\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e157d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      5000\n",
      "           1       0.94      0.95      0.94      5000\n",
      "           2       0.84      0.81      0.82      5000\n",
      "           3       0.97      0.97      0.97      5000\n",
      "           4       0.93      0.93      0.93      5000\n",
      "           5       0.93      0.95      0.94      5000\n",
      "           6       0.92      0.92      0.92      5000\n",
      "           7       0.96      0.97      0.97      5000\n",
      "           8       0.99      0.98      0.98      5000\n",
      "           9       0.97      0.97      0.97      5000\n",
      "          10       0.97      0.97      0.97      5000\n",
      "          11       0.94      0.96      0.95      5000\n",
      "          12       0.94      0.95      0.94      5000\n",
      "          13       0.86      0.86      0.86      5000\n",
      "\n",
      "    accuracy                           0.93     70000\n",
      "   macro avg       0.93      0.93      0.93     70000\n",
      "weighted avg       0.93      0.93      0.93     70000\n",
      "\n",
      "confusion matrix:\n",
      "[[4259   51   94   17   37  171   86   16    0    6    9   54   36  164]\n",
      " [  65 4726   22   11   48    9   74   12    5    2    2    0    6   18]\n",
      " [  95   36 4042   32  115   10   36    4    0    3    6  198   92  331]\n",
      " [  11    9   72 4847   16   18    6    3    0    5    1    0    3    9]\n",
      " [  37   64  120   26 4661   22   27    2    1    4    1    0    7   28]\n",
      " [ 152    4    5    3   12 4764   26   11    1    6    0    1    3   12]\n",
      " [ 110   81   30    5   45   44 4590   57   13    3    1    0    6   15]\n",
      " [  10    1    1    1    6   17   58 4864   16    8    5    0    2   11]\n",
      " [   2    7    1    1    7    1   42   46 4887    1    2    0    0    3]\n",
      " [   4    1    5    6    2    3    7    9    0 4833  123    1    1    5]\n",
      " [  19    1    6    0    1    4    3    7    0  106 4849    2    0    2]\n",
      " [  16    0  112    2    3    2    1    2    0    2    2 4805   36   17]\n",
      " [  11    1   66    8    6    9    2    1    0    5    4   32 4742  113]\n",
      " [ 139   28  232   22   46   22   27    9    2    8    4   23  116 4322]]\n"
     ]
    }
   ],
   "source": [
    "score1 = metrics.accuracy_score(y_test, pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4bad1",
   "metadata": {},
   "source": [
    "### tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033aafa7",
   "metadata": {},
   "source": [
    "### one fourth of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f9ff91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to extract features from training data : 2.241900 seconds\n",
      "n_samples: 93334, n_features: 215944\n",
      "Time taken to extract features from test data : 1.360001 seconds\n",
      "n_samples: 70000, n_features: 215944\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[01:23:04] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/tree/updater_gpu_hist.cu:784: Exception in gpu_hist: [01:23:04] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1\\xgboost\\xgboost-ci-windows\\src\\data\\../common/device_helpers.cuh:431: Memory allocation error on worker 0: bad allocation: cudaErrorMemoryAllocation: out of memory\n- Free memory: 1103390311\n- Requested memory: 2426767616\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m## TRAIN AND FIT CLASSIFIER\u001b[39;00m\n\u001b[0;32m     49\u001b[0m t \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m---> 50\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m training_time \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m-\u001b[39m t\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain time: \u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m training_time)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [01:23:04] C:/buildkite-agent/builds/buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1/xgboost/xgboost-ci-windows/src/tree/updater_gpu_hist.cu:784: Exception in gpu_hist: [01:23:04] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-030221e36e1a46bfb-1\\xgboost\\xgboost-ci-windows\\src\\data\\../common/device_helpers.cuh:431: Memory allocation error on worker 0: bad allocation: cudaErrorMemoryAllocation: out of memory\n- Free memory: 1103390311\n- Requested memory: 2426767616\n\n"
     ]
    }
   ],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_preprocessed.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_preprocessed.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "y_train = y_train[slice(0, len(y_train), 6)]\n",
    "x_train = x_train[slice(0, len(x_train), 6)]\n",
    "\n",
    "y_train = [y-1 for y in y_train]\n",
    "y_test = [y-1 for y in y_test]\n",
    "\n",
    "\n",
    "## TFIDF VECTORIZATION\n",
    "\n",
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = TfidfVectorizer() # or term frequency\n",
    "\n",
    "x_train = tf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "\n",
    "t = time()\n",
    "x_test = tf_vectorizer.transform(x_test)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "del x_train\n",
    "del x_test\n",
    "del tf_vectorizer\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "## TRAIN AND FIT CLASSIFIER\n",
    "\n",
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d24890",
   "metadata": {},
   "source": [
    "### half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f786c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_preprocessed.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_preprocessed.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "y_train = y_train[slice(0, len(y_train), 2)]\n",
    "x_train = x_train[slice(0, len(x_train), 2)]\n",
    "\n",
    "y_train = [y-1 for y in y_train]\n",
    "y_test = [y-1 for y in y_test]\n",
    "\n",
    "\n",
    "## TFIDF VECTORIZATION\n",
    "\n",
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = TfidfVectorizer() # or term frequency\n",
    "\n",
    "x_train = tf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "\n",
    "t = time()\n",
    "x_test = tf_vectorizer.transform(x_test)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "del x_train\n",
    "del x_test\n",
    "del tf_vectorizer\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "## TRAIN AND FIT CLASSIFIER\n",
    "\n",
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c76dd",
   "metadata": {},
   "source": [
    "### full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3569dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, _, x_train = pickle.load(open(\"dbpedia_csv/\" + \"/train_preprocessed.pickle\", \"rb\"))\n",
    "#_, _, x_valid = pickle.load(open(paths.data + \"/validation_preprocessed.pickle\", \"rb\"))\n",
    "y_test, _, x_test = pickle.load(open(\"dbpedia_csv/\" + \"/test_preprocessed.pickle\", \"rb\"))\n",
    "\n",
    "y_train = [y-1 for y in y_train]\n",
    "y_test = [y-1 for y in y_test]\n",
    "\n",
    "\n",
    "## TFIDF VECTORIZATION\n",
    "\n",
    "t = time()  # not compulsory\n",
    "\n",
    "# loading CountVectorizer\n",
    "tf_vectorizer = TfidfVectorizer() # or term frequency\n",
    "\n",
    "x_train = tf_vectorizer.fit_transform(x_train)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from training data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_train.shape)\n",
    "\n",
    "t = time()\n",
    "x_test = tf_vectorizer.transform(x_test)\n",
    "\n",
    "duration = time() - t\n",
    "print(\"Time taken to extract features from test data : %f seconds\" % (duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(data=x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(data=x_test)\n",
    "\n",
    "\n",
    "import gc\n",
    "import sys\n",
    "del x_train\n",
    "del x_test\n",
    "del tf_vectorizer\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "## TRAIN AND FIT CLASSIFIER\n",
    "\n",
    "t = time()\n",
    "bst = xgb.train(params, dtrain)\n",
    "\n",
    "training_time = time() - t\n",
    "print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "\n",
    "t = time()\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "test_time = time() - t\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "# compute the performance measures\n",
    "score1 = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:   %0.3f\" % score1)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=[str(x) for x in range(14)]))\n",
    "\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
